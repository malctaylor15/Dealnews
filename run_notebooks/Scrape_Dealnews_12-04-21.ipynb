{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bs4 \n",
    "import re \n",
    "import os \n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "import urllib\n",
    "from dateutil import parser\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import sqlite3\n",
    "pd.set_option('max_colwidth', 300)\n",
    "pd.set_option('max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Fun Fact.. Dealnews uses an API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dealnews_feed(link):\n",
    "    headers = {'Authorization': 'DN jxqfz29pbv9xpWSYnmJX'}\n",
    "    dealnews = requests.get(link, headers=headers)\n",
    "    assert(dealnews.status_code == 200), f\"Status Code={dealnews.status_code}...Error:\\n\\n{dealnews.content}\"\n",
    "    as_json = json.loads(dealnews.content)\n",
    "    return(as_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Understanding API Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _parse_api_deal_types(raw_api_response):\n",
    "    ## Deal Types\n",
    "    keeper_elems = ['name', 'count', 'url', 'short_name']\n",
    "    groups = raw_api_response['deal_types']\n",
    "    key_group_info = []\n",
    "    for group in groups:\n",
    "        key_group_info.append([group[x] for x in keeper_elems])\n",
    "    deal_type_df = pd.DataFrame(key_group_info, columns = keeper_elems)\n",
    "    deal_type_df = deal_type_df.rename({'url': 'id_number'}, axis =1)\n",
    "    deal_type_df['id_name'] = 'deal_type_id'\n",
    "    return(deal_type_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _parse_api_categories(raw_api_response):\n",
    "    ## Categories\n",
    "    keeper_elems = ['name', 'count', 'category_id', 'short_name']\n",
    "    groups = raw_api_response['categories']\n",
    "    key_group_info = []\n",
    "    for group in groups:\n",
    "        key_group_info.append([group[x] for x in keeper_elems])\n",
    "    category_df = pd.DataFrame(key_group_info, columns = keeper_elems)\n",
    "    category_df = category_df.rename({'category_id': 'id_number'}, axis =1)\n",
    "    category_df['id_name'] = 'category_id'\n",
    "    return(category_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _parse_api_brands(raw_api_response):\n",
    "    ## Brands\n",
    "    keeper_elems = ['name', 'count', 'brand_id', 'short_name']\n",
    "    groups = raw_api_response['brands']\n",
    "    key_group_info = []\n",
    "    for group in groups:\n",
    "        key_group_info.append([group[x] for x in keeper_elems])\n",
    "    brand_df = pd.DataFrame(key_group_info, columns = keeper_elems)\n",
    "    brand_df = brand_df.rename({'brand_id': 'id_number'}, axis =1)\n",
    "    brand_df['id_name'] = 'brand_id'\n",
    "    return(brand_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _parse_api_vendors(raw_api_response):\n",
    "    ## Vendors\n",
    "    keeper_elems = ['name', 'count', 'vendor_id', 'short_name']\n",
    "    groups = raw_api_response['vendors']\n",
    "    key_group_info = []\n",
    "    for group in groups:\n",
    "        key_group_info.append([group[x] for x in keeper_elems])\n",
    "    vendor_df = pd.DataFrame(key_group_info, columns = keeper_elems)\n",
    "    vendor_df = vendor_df.rename({'vendor_id': 'id_number'}, axis =1)\n",
    "    vendor_df['id_name'] = 'vendor_id'\n",
    "    return(vendor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _parse_api_facet_groups(raw_api_response):\n",
    "    ## Facet Groups \n",
    "    keeper_elems = ['name', 'count', 'facet_id', 'short_name']\n",
    "    facet_group = raw_api_response['facet_groups']\n",
    "    key_group_info = []\n",
    "    # This one has a group within each group (2 levels before getting to the mapping)\n",
    "    for facet in facet_group:\n",
    "        groups = facet['facets']\n",
    "        facet_category_name = facet['name']\n",
    "        for group in groups:\n",
    "            group_list = [facet_category_name + ' : ' + group[x] if x == 'name' \n",
    "                          else group[x] for x in keeper_elems]\n",
    "            key_group_info.append(group_list)\n",
    "    facet_df = pd.DataFrame(key_group_info, columns = keeper_elems)\n",
    "    facet_df = facet_df.rename({'facet_id': 'id_number'}, axis =1)\n",
    "    facet_df['id_name'] = 'facet_id'\n",
    "    return(facet_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Summarize Options "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_summary_of_api_options(df):\n",
    "    out = {}\n",
    "    out['Offers Sum'] = df['count'].sum()\n",
    "    out['Group Count'] = df.shape[0]\n",
    "    df = df.sort_values(by='count', ascending=False)\n",
    "    most_common = df.iloc[0]\n",
    "    out['Most Common Name'] = most_common['name']\n",
    "    out['Most Common Count'] = most_common['count']\n",
    "    out['Most Common ID'] = most_common['id_number']\n",
    "    \n",
    "    out_series = pd.Series(out)\n",
    "    return(out_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Begin Running it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Parse API Categories with Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "con = sqlite3.connect('dealnews.db')\n",
    "cursor = con.cursor()\n",
    "\n",
    "tables = cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\").fetchall()\n",
    "tables = [x[0] for x in tables]\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "link = 'https://api.dealnews.com/content?facet_ids=1780&count=70'\n",
    "raw_api_response = get_dealnews_feed(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "deal_types_df = _parse_api_deal_types(raw_api_response)\n",
    "vendor_df = _parse_api_vendors(raw_api_response)\n",
    "facet_df = _parse_api_facet_groups(raw_api_response)\n",
    "brand_df = _parse_api_brands(raw_api_response)\n",
    "category_df = _parse_api_categories(raw_api_response)\n",
    "\n",
    "\n",
    "df_type = {\n",
    "#     \"deal_type\" : deal_types_df, # not really helpful with the API calls \n",
    "\"vendor\" : vendor_df,\n",
    "\"facet_group\" : facet_df,\n",
    "\"brand\" : brand_df,\n",
    "\"category\" : category_df}\n",
    "\n",
    "all_dfs = pd.concat(df_type)\n",
    "all_dfs.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary1 = all_dfs.reset_index().groupby('level_0')\\\n",
    "    .apply(get_summary_of_api_options)\n",
    "summary1.index = summary1.index.rename('API Category Name')\n",
    "summary1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Save to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_dfs['_dt_pulled'] = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "all_dfs.to_sql('Category Info', con, if_exists='append')\n",
    "\n",
    "summary1['_dt_pulled'] = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "summary1.to_sql('Category Summary', con, if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Parse One API Section Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     41,
     47,
     53,
     67,
     73,
     89
    ],
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def parse_easy_elems(content):\n",
    "    content_keys_to_keep = [\n",
    "         'id',\n",
    "         'headline',\n",
    "         'brief_headline',\n",
    "         'summary',\n",
    "         'secondary_summary',\n",
    "         'key_attribute',\n",
    "         'brief_notes',\n",
    "         'url',\n",
    "         'display_date',\n",
    "         'publish_datetime_ts',\n",
    "         'update_datetime_ts',\n",
    "         'expiration_datetime_ts',\n",
    "         'last_verified_datetime_ts',\n",
    "         'editors_choice',\n",
    "         'sponsored',\n",
    "         'expired',\n",
    "         'expires_today',\n",
    "         'exclusive',\n",
    "         'searchable',\n",
    "         'hotness',\n",
    "         'call_out',\n",
    "         'call_out_comparison',\n",
    "         'sub_call_out'\n",
    "    ]\n",
    "    out_dict = {x : content[x] for x in content_keys_to_keep}\n",
    "    return(out_dict)\n",
    "\n",
    "def parse_time_fields(content):\n",
    "    elements = ['publish_datetime_ts',\n",
    "         'update_datetime_ts',\n",
    "         'expiration_datetime_ts',\n",
    "         'last_verified_datetime_ts']\n",
    "    out_dict = {}\n",
    "    for x in elements:\n",
    "        temp_time = content.get(x) if content.get(x) != None else 0\n",
    "        temp_time = datetime.datetime.fromtimestamp(temp_time)\n",
    "        out_dict[x] = datetime.datetime.strftime(temp_time, '%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "    return(out_dict)\n",
    "\n",
    "def parse_coupon_code(content):\n",
    "    cc_list = content['coupon_code']\n",
    "    cc_code = cc_list[0] if len(cc_list) > 0 else None \n",
    "    out_dict = {\"Coupon Code\":cc_code}\n",
    "    return(out_dict)\n",
    "\n",
    "def _parse_category(cat_dict):\n",
    "    keeper_elements = ['category_id', 'name'\n",
    "                      'path', 'ancestor_list' ]\n",
    "    cat_elems = {x:cat_dict.get(x) for x in keeper_elements}\n",
    "    return(cat_elems)\n",
    "\n",
    "def parse_2_categories(content):\n",
    "    cat_list = content['categories']\n",
    "    out_dict = {}\n",
    "    # Only keep 2 categories \n",
    "    if len(cat_list) < 2:\n",
    "        cat_list.append({})\n",
    "    for dict_num in range(2):\n",
    "        temp_cat_elems = _parse_category(cat_list[dict_num])\n",
    "        temp_cat_elems = {key + '_' +str(dict_num): value \n",
    "                          for key, value in temp_cat_elems.items()}\n",
    "        out_dict.update(temp_cat_elems)\n",
    "    \n",
    "    return(out_dict)\n",
    "\n",
    "def parse_vendor(content):\n",
    "    vend_dict = content['vendor']\n",
    "    keeper_elems = ['vendor_id', 'name']\n",
    "    vend_dict = {x:vend_dict[x] for x in keeper_elems}\n",
    "    return(vend_dict)\n",
    "\n",
    "def _create_img_path(content):\n",
    "    # Create Filename\n",
    "    headline = content.get('headline')\n",
    "    id1 = content.get('id')\n",
    "    file_name = headline + '_' + str(id1) + '.jpg'\n",
    "    file_name = file_name.replace('/', '')\n",
    "    # Create Directory structure \n",
    "    date = str(datetime.datetime.now().date())\n",
    "    base_path = '/mnt/volume-nyc3-01/Dealnews_Images/'\n",
    "    path = base_path + date + '/'\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    #File Save location \n",
    "    save_location = path + file_name\n",
    "    return(save_location)\n",
    "    \n",
    "def parse_image(content):\n",
    "    image_link = content.get('images').get('XXL').get('url')\n",
    "    save_path = _create_img_path(content)\n",
    "    \n",
    "    urllib.request.urlretrieve(image_link, save_path)\n",
    "    out_dict = {'Image path': save_path}\n",
    "    return(out_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_dn_item(content):\n",
    "    all_details = {}\n",
    "    \n",
    "    main_elems = parse_easy_elems(content)\n",
    "    all_details.update(main_elems)\n",
    "    \n",
    "    time_fields = parse_time_fields(content)\n",
    "    all_details.update(time_fields)\n",
    "    \n",
    "    cc_code = parse_coupon_code(content)\n",
    "    all_details.update(cc_code)\n",
    "    \n",
    "    categories = parse_2_categories(content)\n",
    "    all_details.update(categories)\n",
    "\n",
    "    vendor = parse_vendor(content)\n",
    "    all_details.update(vendor)\n",
    "    \n",
    "    image_info = parse_image(content)\n",
    "    all_details.update(image_info)\n",
    "    \n",
    "    return(all_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _get(colname):\n",
    "    return(popularity.columns.tolist().index(colname))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "source": [
    "facet_groups = [x['name'] for x in raw_api_response['facet_groups']]\n",
    "facet_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "popularity = facet_df[facet_df.name.str.contains('Popularity Rank')]\n",
    "# popularity['n_api_return_items'] = 70\n",
    "# popularity['# of times to call'] = popularity['count']/popularity['n_api_return_items']\n",
    "# popularity['# of times to call'] = 1 + popularity['# of times to call'].astype('int')\n",
    "# popularity['# of times to call'] = 3\n",
    "popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_published_item_raw = cursor.execute(\"\"\"\n",
    "select `API Feed`, max(publish_datetime_ts) \n",
    "from `Dealnews Items`\n",
    "group by `API Feed`\n",
    "\"\"\").fetchall()\n",
    "\n",
    "# For all the items \n",
    "# last_published_dict = {x: str(datetime.datetime(1980, 1, 1)) for x in popularity['name'].tolist()}\n",
    "last_published_dict = {x[0]: str(datetime.datetime.strptime(x[1], '%Y-%m-%d %H:%M:%S')) for x in last_published_item_raw}\n",
    "last_published_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_path = '/mnt/volume-nyc3-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "page_items = []\n",
    "for row in popularity.iterrows():\n",
    "    # Set up \n",
    "    row = row[1]\n",
    "    print(\"On group: \\n\", row)\n",
    "    temp_name = row[_get('name')]\n",
    "    id_num = row[_get('id_number')]\n",
    "    temp_link = f'https://api.dealnews.com/content?facet_ids={id_num}&count=70'\n",
    "    raw_api_response = get_dealnews_feed(temp_link)\n",
    "    last_published_item = last_published_dict[temp_name]\n",
    "    \n",
    "    # Parse each item \n",
    "    for content1 in tqdm(raw_api_response['content']):\n",
    "        elems = parse_dn_item(content1)\n",
    "        elems['API Feed'] = temp_name\n",
    "        elems['API id_number'] = id_num\n",
    "        elems_series = pd.Series(elems)\n",
    "        item_publish_time = elems_series['publish_datetime_ts'] \n",
    "        if item_publish_time > last_published_item:\n",
    "            page_items.append(elems_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(page_items) > 0:\n",
    "    dn_today = pd.concat(page_items, axis =1).T\n",
    "    print(f\"Saving {dn_today.shape[0]} items\") \n",
    "    dn_today['_dt_pulled'] = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "    dn_today.to_sql('Dealnews Items', con, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 67.428826,
   "end_time": "2021-12-05T02:38:11.622164",
   "environment_variables": {},
   "exception": null,
   "input_path": "Scrape_Dealnews.ipynb",
   "output_path": "run_notebooks/Scrape_Dealnews_12-04-21.ipynb",
   "parameters": {},
   "start_time": "2021-12-05T02:37:04.193338",
   "version": "2.2.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}